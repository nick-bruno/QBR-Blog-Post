{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "474697dd",
   "metadata": {},
   "source": [
    "# Scrape Statheads Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4808219a",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b485f13",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "import pandas as pd\n",
    "import time\n",
    "import os\n",
    "import getpass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d595687",
   "metadata": {},
   "source": [
    "### Read in Statheads Credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca87da37",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./stathead_credentials/stathead_credentials.txt', \"r\") as text_file:\n",
    "    creds = text_file.readlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a845fbbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats_username = creds[0].split('=')[1].strip('')\n",
    "stats_password = creds[1].split('=')[1].strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea1cf60",
   "metadata": {},
   "source": [
    "## Scrape from Statheads (Playoffs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3868e0f",
   "metadata": {},
   "source": [
    "## Scraping Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "769100a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def login_to_stathead(driver, username, password):\n",
    "    \"\"\"Handle the login process for Stathead\"\"\"\n",
    "    print(\"Attempting to log in to Stathead...\")\n",
    "    #chrome_options = Options()\n",
    "    #chrome_options.add_argument(\"--no-sandbox\")\n",
    "    #chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    #chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    #chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    #chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    #chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    #\n",
    "    ## Keep browser visible for debugging\n",
    "    ## chrome_options.add_argument(\"--headless\")\n",
    "    #\n",
    "    #driver = webdriver.Chrome(options=chrome_options)\n",
    "    #driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    \n",
    "    wait = WebDriverWait(driver, 15)\n",
    "    \n",
    "    try:\n",
    "        # Go to the login page first\n",
    "        login_url = \"https://stathead.com/users/login.cgi\"\n",
    "        driver.get(login_url)\n",
    "        time.sleep(5)  # Increased wait time\n",
    "        \n",
    "        print(\"Looking for login form...\")\n",
    "        \n",
    "        # Debug: Show all input fields on the page\n",
    "        print(\"Available input fields:\")\n",
    "        all_inputs = driver.find_elements(By.TAG_NAME, \"input\")\n",
    "        for i, inp in enumerate(all_inputs):\n",
    "            try:\n",
    "                inp_type = inp.get_attribute('type') or 'text'\n",
    "                inp_name = inp.get_attribute('name') or ''\n",
    "                inp_id = inp.get_attribute('id') or ''\n",
    "                inp_placeholder = inp.get_attribute('placeholder') or ''\n",
    "                inp_class = inp.get_attribute('class') or ''\n",
    "                print(f\"  {i+1}. type='{inp_type}', name='{inp_name}', id='{inp_id}', placeholder='{inp_placeholder}', class='{inp_class}'\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Find username field with multiple selectors\n",
    "        username_selectors = [\n",
    "            \"input[name='username']\",\n",
    "            \"input[name='email']\", \n",
    "            \"input[type='email']\",\n",
    "            \"input[id='username']\",\n",
    "            \"input[id='email']\",\n",
    "            \"input[placeholder*='username']\",\n",
    "            \"input[placeholder*='email']\",\n",
    "            \"input[placeholder*='Username']\",\n",
    "            \"input[placeholder*='Email']\"\n",
    "        ]\n",
    "        \n",
    "        username_field = None\n",
    "        username_selector_used = None\n",
    "        for selector in username_selectors:\n",
    "            try:\n",
    "                username_field = wait.until(EC.presence_of_element_located((By.CSS_SELECTOR, selector)))\n",
    "                username_selector_used = selector\n",
    "                print(f\"✅ Found username field with: {selector}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not username_field:\n",
    "            print(\"❌ Username field not found with any selector\")\n",
    "            return False\n",
    "        \n",
    "        # Find password field with multiple selectors and better waiting\n",
    "        password_selectors = [\n",
    "            \"input[type='password']\",\n",
    "            \"input[name='password']\",\n",
    "            \"input[id='password']\",\n",
    "            \"input[placeholder*='password']\",\n",
    "            \"input[placeholder*='Password']\"\n",
    "        ]\n",
    "        \n",
    "        password_field = None\n",
    "        password_selector_used = None\n",
    "        for selector in password_selectors:\n",
    "            try:\n",
    "                # Wait for password field to be present and visible\n",
    "                password_field = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "                password_selector_used = selector\n",
    "                print(f\"✅ Found password field with: {selector}\")\n",
    "                break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        if not password_field:\n",
    "            print(\"❌ Password field not found with any selector\")\n",
    "            return False\n",
    "        \n",
    "        # Enter username first\n",
    "        print(\"Entering username...\")\n",
    "        try:\n",
    "            # Click on username field first to ensure focus\n",
    "            username_field.click()\n",
    "            time.sleep(0.5)\n",
    "            username_field.clear()\n",
    "            time.sleep(0.5)\n",
    "            username_field.send_keys(username)\n",
    "            print(\"✅ Username entered successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error entering username: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # Small delay before password\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Enter password\n",
    "        print(\"Entering password...\")\n",
    "        try:\n",
    "            # Click on password field to ensure focus\n",
    "            password_field.click()\n",
    "            time.sleep(0.5)\n",
    "            password_field.clear()\n",
    "            time.sleep(0.5)\n",
    "            \n",
    "            # Type password slowly to avoid issues\n",
    "            for char in password:\n",
    "                password_field.send_keys(char)\n",
    "                time.sleep(0.1)  # Small delay between characters\n",
    "            \n",
    "            print(\"✅ Password entered successfully\")\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error entering password: {e}\")\n",
    "            return False\n",
    "        \n",
    "        # Wait a moment before submitting\n",
    "        time.sleep(1)\n",
    "        \n",
    "        # Try multiple submission methods\n",
    "        submission_successful = False\n",
    "        \n",
    "        # Method 1: Press Enter on password field\n",
    "        try:\n",
    "            password_field.send_keys(Keys.RETURN)\n",
    "            print(\"✅ Submitted form with Enter key\")\n",
    "            submission_successful = True\n",
    "        except Exception as e:\n",
    "            print(f\"Method 1 (Enter key) failed: {e}\")\n",
    "        \n",
    "        # Method 2: Find and click submit button\n",
    "        if not submission_successful:\n",
    "            try:\n",
    "                submit_selectors = [\n",
    "                    \"input[type='submit']\",\n",
    "                    \"button[type='submit']\",\n",
    "                    \"input[value*='Log in']\",\n",
    "                    \"input[value*='Sign in']\",\n",
    "                    \"button[id*='login']\",\n",
    "                    \"button[id*='signin']\",\n",
    "                    \"button[class*='submit']\",\n",
    "                    \"button[class*='login']\"\n",
    "                ]\n",
    "                \n",
    "                submit_button = None\n",
    "                for selector in submit_selectors:\n",
    "                    try:\n",
    "                        submit_button = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "                        if submit_button.is_displayed() and submit_button.is_enabled():\n",
    "                            break\n",
    "                    except:\n",
    "                        continue\n",
    "                \n",
    "                if submit_button:\n",
    "                    submit_button.click()\n",
    "                    print(\"✅ Clicked submit button\")\n",
    "                    submission_successful = True\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"Method 2 (submit button) failed: {e}\")\n",
    "        \n",
    "        # Method 3: Submit the form via JavaScript\n",
    "        if not submission_successful:\n",
    "            try:\n",
    "                driver.execute_script(\"document.forms[0].submit();\")\n",
    "                print(\"✅ Submitted form via JavaScript\")\n",
    "                submission_successful = True\n",
    "            except Exception as e:\n",
    "                print(f\"Method 3 (JavaScript submit) failed: {e}\")\n",
    "        \n",
    "        if not submission_successful:\n",
    "            print(\"❌ Could not submit login form\")\n",
    "            return False\n",
    "        \n",
    "        # Wait longer for login to complete\n",
    "        print(\"Waiting for login to complete...\")\n",
    "        time.sleep(8)\n",
    "        \n",
    "        # Check if login was successful with multiple indicators\n",
    "        current_url = driver.current_url\n",
    "        page_source = driver.page_source.lower()\n",
    "        \n",
    "        success_indicators = [\n",
    "            'logout' in page_source,\n",
    "            'sign out' in page_source,\n",
    "            'account' in page_source,\n",
    "            'profile' in page_source,\n",
    "            'dashboard' in current_url,\n",
    "            'login' not in current_url\n",
    "        ]\n",
    "        \n",
    "        failure_indicators = [\n",
    "            'error' in page_source,\n",
    "            'invalid' in page_source,\n",
    "            'incorrect' in page_source,\n",
    "            'failed' in page_source,\n",
    "            'try again' in page_source\n",
    "        ]\n",
    "        \n",
    "        if any(success_indicators):\n",
    "            print(\"✅ Login appears successful!\")\n",
    "            return True\n",
    "        elif any(failure_indicators):\n",
    "            print(\"❌ Login failed - error detected on page\")\n",
    "            print(\"Page URL:\", current_url)\n",
    "            # Show some of the page content for debugging\n",
    "            print(\"Page content preview:\", page_source[:500])\n",
    "            return False\n",
    "        else:\n",
    "            print(\"⚠️ Login status unclear, continuing anyway...\")\n",
    "            print(\"Page URL:\", current_url)\n",
    "            return True\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Login error: {e}\")\n",
    "        # Take screenshot for debugging\n",
    "        try:\n",
    "            driver.save_screenshot(\"login_debug.png\")\n",
    "            print(\"Debug screenshot saved: login_debug.png\")\n",
    "        except:\n",
    "            pass\n",
    "        return False\n",
    "\n",
    "def find_next_page_button(driver):\n",
    "    \"\"\"Find the Next Page button using multiple strategies\"\"\"\n",
    "    \n",
    "    next_page_selectors = [\n",
    "        # Text-based searches\n",
    "        \"//a[contains(text(), 'Next')]\",\n",
    "        \"//button[contains(text(), 'Next')]\",\n",
    "        \"//a[contains(text(), 'next')]\",\n",
    "        \"//button[contains(text(), 'next')]\",\n",
    "        \"//a[contains(text(), 'Next Page')]\",\n",
    "        \"//button[contains(text(), 'Next Page')]\",\n",
    "        \n",
    "        # Common pagination patterns\n",
    "        \"//a[@title='Next Page']\",\n",
    "        \"//button[@title='Next Page']\",\n",
    "        \"//a[@title='Next']\",\n",
    "        \"//button[@title='Next']\",\n",
    "        \n",
    "        # Class-based searches (common pagination classes)\n",
    "        \"//a[contains(@class, 'next')]\",\n",
    "        \"//button[contains(@class, 'next')]\",\n",
    "        \"//a[contains(@class, 'page-next')]\",\n",
    "        \"//button[contains(@class, 'page-next')]\",\n",
    "        \n",
    "        # Arrow symbols\n",
    "        \"//a[contains(text(), '→')]\",\n",
    "        \"//button[contains(text(), '→')]\",\n",
    "        \"//a[contains(text(), '>')]\",\n",
    "        \"//button[contains(text(), '>')]\",\n",
    "        \n",
    "        # Rel attribute (HTML standard for pagination)\n",
    "        \"//a[@rel='next']\",\n",
    "        \n",
    "        # Sports Reference specific patterns\n",
    "        \"//a[contains(@href, 'offset=')]\",\n",
    "        \"//a[contains(@href, 'page=')]\"\n",
    "    ]\n",
    "    \n",
    "    for selector in next_page_selectors:\n",
    "        try:\n",
    "            elements = driver.find_elements(By.XPATH, selector)\n",
    "            for element in elements:\n",
    "                # Check if element is visible and clickable\n",
    "                if element.is_displayed() and element.is_enabled():\n",
    "                    # Additional check - make sure it's not disabled\n",
    "                    classes = element.get_attribute('class') or ''\n",
    "                    if 'disabled' not in classes.lower():\n",
    "                        return element\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return None\n",
    "\n",
    "def scrape_page_table(driver, page_num):\n",
    "    \"\"\"Scrape table data from current page\"\"\"\n",
    "    print(f\"Scraping page {page_num}...\")\n",
    "    \n",
    "    # Wait for table to load\n",
    "    wait = WebDriverWait(driver, 10)\n",
    "    time.sleep(2)  # Give page time to fully load\n",
    "    \n",
    "    # Find the main data table\n",
    "    table_selectors = [\n",
    "        \"#stats\",\n",
    "        \"#results\", \n",
    "        \".stats_table\",\n",
    "        \".sortable\",\n",
    "        \"table[id*='stats']\",\n",
    "        \"table[class*='stats']\"\n",
    "    ]\n",
    "    \n",
    "    table = None\n",
    "    for selector in table_selectors:\n",
    "        try:\n",
    "            tables = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if tables:\n",
    "                table = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, \"tr\")))\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not table:\n",
    "        print(f\"❌ No table found on page {page_num}\")\n",
    "        return []\n",
    "    \n",
    "    # Extract data rows (skip headers since we'll get them from first page)\n",
    "    data_rows = []\n",
    "    try:\n",
    "        tbody = table.find_element(By.TAG_NAME, \"tbody\")\n",
    "        rows = tbody.find_elements(By.TAG_NAME, \"tr\")\n",
    "    except:\n",
    "        # Fallback: get all rows\n",
    "        all_rows = table.find_elements(By.TAG_NAME, \"tr\")\n",
    "        # Skip first row if it contains only th elements (header)\n",
    "        rows = []\n",
    "        for row in all_rows:\n",
    "            if row.find_elements(By.TAG_NAME, \"td\"):  # Has data cells\n",
    "                rows.append(row)\n",
    "    \n",
    "    for i, row in enumerate(rows):\n",
    "        try:\n",
    "            # Skip rows that are just headers\n",
    "            if row.find_elements(By.TAG_NAME, \"th\") and not row.find_elements(By.TAG_NAME, \"td\"):\n",
    "                continue\n",
    "            \n",
    "            cells = row.find_elements(By.TAG_NAME, \"td\")\n",
    "            if not cells:\n",
    "                continue\n",
    "            \n",
    "            row_data = []\n",
    "            for cell in cells:\n",
    "                cell_text = cell.text.strip()\n",
    "                \n",
    "                # Handle links\n",
    "                if not cell_text:\n",
    "                    link = cell.find_elements(By.TAG_NAME, \"a\")\n",
    "                    if link:\n",
    "                        cell_text = link[0].text.strip()\n",
    "                \n",
    "                # Handle data attributes\n",
    "                if not cell_text:\n",
    "                    cell_text = cell.get_attribute('data-stat') or ''\n",
    "                \n",
    "                row_data.append(cell_text)\n",
    "            \n",
    "            if row_data:\n",
    "                data_rows.append(row_data)\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing row {i} on page {page_num}: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"✅ Page {page_num}: extracted {len(data_rows)} rows\")\n",
    "    return data_rows\n",
    "\n",
    "def get_table_headers(driver):\n",
    "    \"\"\"Extract table headers from the first page\"\"\"\n",
    "    table_selectors = [\n",
    "        \"#stats\",\n",
    "        \"#results\", \n",
    "        \".stats_table\",\n",
    "        \".sortable\",\n",
    "        \"table[id*='stats']\",\n",
    "        \"table[class*='stats']\"\n",
    "    ]\n",
    "    \n",
    "    table = None\n",
    "    for selector in table_selectors:\n",
    "        try:\n",
    "            tables = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if tables:\n",
    "                table = max(tables, key=lambda t: len(t.find_elements(By.TAG_NAME, \"tr\")))\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not table:\n",
    "        return []\n",
    "    \n",
    "    headers = []\n",
    "    try:\n",
    "        thead = table.find_element(By.TAG_NAME, \"thead\")\n",
    "        header_rows = thead.find_elements(By.TAG_NAME, \"tr\")\n",
    "        header_row = header_rows[-1]  # Last header row usually has column names\n",
    "        header_cells = header_row.find_elements(By.TAG_NAME, \"th\")\n",
    "        \n",
    "        for cell in header_cells:\n",
    "            header_text = cell.text.strip()\n",
    "            if not header_text:\n",
    "                header_text = cell.get_attribute('data-stat') or cell.get_attribute('aria-label') or ''\n",
    "            headers.append(header_text)\n",
    "    except:\n",
    "        # Fallback: use first data row structure to determine column count\n",
    "        try:\n",
    "            first_data_row = table.find_element(By.XPATH, \".//tr[td]\")\n",
    "            cells = first_data_row.find_elements(By.TAG_NAME, \"td\")\n",
    "            headers = [f\"Column_{i+1}\" for i in range(len(cells))]\n",
    "        except:\n",
    "            headers = []\n",
    "    \n",
    "    return headers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4f7f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_all_pages_playoffs(username, password, url):\n",
    "    \"\"\"Scrape all pages by clicking Next until no more pages\"\"\"\n",
    "    \n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--no-sandbox\")\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControlled\")\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    chrome_options.add_argument(\"--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\")\n",
    "    \n",
    "    # Keep browser visible for debugging\n",
    "    # chrome_options.add_argument(\"--headless\")\n",
    "    \n",
    "    driver = webdriver.Chrome(options=chrome_options)\n",
    "    driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "    #\n",
    "    ##wait = WebDriverWait(driver, 15)\n",
    "    \n",
    "    all_data = []\n",
    "    headers = []\n",
    "    \n",
    "    try:\n",
    "        # Step 1: Login\n",
    "        login_success = login_to_stathead(driver, username, password)\n",
    "        if not login_success:\n",
    "            print(\"Login failed, cannot continue\")\n",
    "            return None\n",
    "        \n",
    "        # Step 2: Navigate to first page\n",
    "        print(f\"Navigating to data page...\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "    \n",
    "        # Step 3: Get headers from first page\n",
    "        print(\"Extracting table headers...\")\n",
    "        headers = get_table_headers(driver)\n",
    "        if not headers:\n",
    "            print(\"❌ Could not extract table headers\")\n",
    "            return None\n",
    "        \n",
    "        print(f\"Found {len(headers)} columns: {headers[:5]}...\" if len(headers) > 5 else f\"Found {len(headers)} columns: {headers}\")\n",
    "        \n",
    "        # Step 4: Scrape all pages\n",
    "        page_num = 1\n",
    "        max_pages = 1000  # Safety limit to prevent infinite loops\n",
    "        \n",
    "        while page_num <= max_pages:\n",
    "            print(f\"\\n--- PAGE {page_num} ---\")\n",
    "            \n",
    "            # Scrape current page\n",
    "            page_data = scrape_page_table(driver, page_num)\n",
    "            if page_data:\n",
    "                all_data.extend(page_data)\n",
    "                print(f\"Total rows collected so far: {len(all_data)}\")\n",
    "            else:\n",
    "                print(f\"No data found on page {page_num}\")\n",
    "            \n",
    "            # Look for Next Page button\n",
    "            print(\"Looking for Next Page button...\")\n",
    "            next_button = find_next_page_button(driver)\n",
    "            \n",
    "            if next_button:\n",
    "                try:\n",
    "                    button_text = next_button.text.strip() or next_button.get_attribute('title') or 'Next'\n",
    "                    print(f\"✅ Found Next Page button: '{button_text}'\")\n",
    "                    \n",
    "                    # Scroll to button and click\n",
    "                    driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_button)\n",
    "                    time.sleep(1)\n",
    "                    \n",
    "                    # Click the button\n",
    "                    next_button.click()\n",
    "                    print(\"✅ Clicked Next Page button\")\n",
    "                    \n",
    "                    # Wait for next page to load\n",
    "                    time.sleep(3)\n",
    "                    \n",
    "                    page_num += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"❌ Error clicking Next Page button: {e}\")\n",
    "                    break\n",
    "            else:\n",
    "                print(\"🏁 No Next Page button found - reached end of data\")\n",
    "                break\n",
    "        \n",
    "        if page_num > max_pages:\n",
    "            print(f\"⚠️ Reached maximum page limit ({max_pages})\")\n",
    "        \n",
    "        print(f\"\\n✅ Scraping complete! Total pages: {page_num-1}\")\n",
    "        print(f\"Total rows collected: {len(all_data)}\")\n",
    "        \n",
    "        # Step 5: Create DataFrame\n",
    "        if not all_data:\n",
    "            print(\"❌ No data collected\")\n",
    "            return None\n",
    "        \n",
    "        # Ensure all rows have same number of columns\n",
    "        max_cols = len(headers) if headers else max(len(row) for row in all_data)\n",
    "        \n",
    "        # Pad headers if necessary\n",
    "        while len(headers) < max_cols:\n",
    "            headers.append(f\"Column_{len(headers) + 1}\")\n",
    "        \n",
    "        # Pad data rows if necessary\n",
    "        for row in all_data:\n",
    "            while len(row) < max_cols:\n",
    "                row.append(\"\")\n",
    "        \n",
    "        # Create DataFrame\n",
    "        df = pd.DataFrame(all_data, columns=headers[:max_cols])\n",
    "        \n",
    "        # Clean data\n",
    "        print(\"Cleaning data...\")\n",
    "        df = df.dropna(axis=1, how='all')  # Remove empty columns\n",
    "        df = df.dropna(axis=0, how='all')  # Remove empty rows\n",
    "        \n",
    "        # Strip whitespace\n",
    "        for col in df.select_dtypes(include=['object']):\n",
    "            df[col] = df[col].astype(str).str.strip()\n",
    "        \n",
    "        print(f\"✅ Final dataset: {len(df)} rows × {len(df.columns)} columns\")\n",
    "        \n",
    "        # Display sample\n",
    "        print(\"\\nFirst 5 rows:\")\n",
    "        print(df.head())\n",
    "        \n",
    "        print(f\"\\nLast 5 rows:\")\n",
    "        print(df.tail())\n",
    "        \n",
    "        # Save to CSV\n",
    "        output_file = \"nfl_qb_stats_all_pages.csv\"\n",
    "        df.to_csv(output_file, index=False)\n",
    "        print(f\"\\n💾 All data saved to: {output_file}\")\n",
    "        \n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error during multi-page scraping: {e}\")\n",
    "        \n",
    "        # Save whatever data we have\n",
    "        if all_data:\n",
    "            try:\n",
    "                df = pd.DataFrame(all_data)\n",
    "                df.to_csv(\"single_game_playoffs_stathead_nfl_qb_stats.csv\", index=False)\n",
    "                print(f\"💾 Partial data saved (rows: {len(all_data)})\")\n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        # Screenshot for debugging\n",
    "        try:\n",
    "            driver.save_screenshot(\"debug_screenshot.png\")\n",
    "            print(\"Screenshot saved: debug_screenshot.png\")\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        return None\n",
    "        \n",
    "    finally:\n",
    "        input(\"\\nPress Enter to close browser...\")\n",
    "        driver.quit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdc058",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"Main function\"\"\"\n",
    "    print(\"=== Stathead Multi-Page Table Scraper ===\")\n",
    "    #print(\"This will scrape ALL pages by automatically clicking 'Next Page'\")\n",
    "    #print()\n",
    "    \n",
    "    # URL to scrape  \n",
    "    #url = \"https://stathead.com/football/player-season-finder.cgi?request=1&comp_type=post&year_max=2025&positions[]=qb&draft_pick_type=overall&match=player_season&year_min=2003&weight_max=500&order_by=pass_rating&rookie=N&season_start=1&season_end=-1&offset=0\"\n",
    "    \n",
    "    url = \"https://stathead.com/football/player-game-finder.cgi?request=1&week_num_season_min=1&season_positions[]=qb&draft_pick_type=overall&player_game_num_season_max=18&year_max=2024&season_start=1&match=player_game&qb_start_num_career_min=1&rookie=N&comp_type=post&timeframe=seasons&year_min=2006&player_game_num_career_max=400&weight_max=500&season_end=-1&team_game_num_season_min=1&team_game_num_season_max=17&qb_start_num_career_max=400&player_game_num_season_min=1&order_by=pass_rating&player_game_num_career_min=1&week_num_season_max=22&cstat[1]=pass_att&ccomp[1]=gt&cval[1]=1&offset=0\"\n",
    "    \n",
    "    # Get credentials\n",
    "    username = stats_username\n",
    "    password = stats_password\n",
    "    \n",
    "    if not username or not password:\n",
    "        print(\"Username and password are required!\")\n",
    "        return\n",
    "    \n",
    "    print(f\"\\nStarting multi-page scrape for user: {username}\")\n",
    "    print(\"This may take several minutes depending on the number of pages...\")\n",
    "    \n",
    "    df = scrape_all_pages_playoffs(username, password, url)\n",
    "    \n",
    "    if df is not None:\n",
    "        print(f\"\\n🎉 SUCCESS! Scraped {len(df)} total rows across all pages\")\n",
    "        print(f\"Data shape: {df.shape}\")\n",
    "        print(f\"Columns: {list(df.columns)}\")\n",
    "        \n",
    "        # Show some statistics\n",
    "        if 'Player' in df.columns:\n",
    "            unique_players = df['Player'].nunique()\n",
    "            print(f\"Unique players: {unique_players}\")\n",
    "        \n",
    "    else:\n",
    "        print(\"\\n❌ Multi-page scraping failed\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017ff05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#login_to_stathead_new('nickbruno', 'Boxdogger1!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "042d55a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
